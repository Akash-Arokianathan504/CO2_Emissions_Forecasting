COâ‚‚ Emissions: Bayesian Regression & Forecasting
This project analyzes and forecasts COâ‚‚ emissions using Bayesian regression models with a Studentâ€™s t-distribution for robustness against outliers.
The workflow covers data ingestion, cleaning, exploratory data analysis (EDA), modeling, and forecasting, focusing on predictors strongly correlated with emissions such as GDP and deforestation.

ðŸ“‚ Repository Structure
graphql
Copy
Edit
co2-emissions-forecasting/
â”œâ”€ README.md
â”œâ”€ .gitignore
â”œâ”€ requirements.txt / pyproject.toml
â”œâ”€ data/
â”‚  â”œâ”€ raw/         # Original datasets (CSV, unmodified)
â”‚  â”œâ”€ processed/   # Cleaned, ready-to-model data
â”œâ”€ notebooks/
â”‚  â”œâ”€ 10-eda.ipynb
â”‚  â”œâ”€ 20-modeling-bayes-trend.ipynb
â”‚  â””â”€ 30-co2-gdp-forecast.ipynb
â”œâ”€ reports/
â”‚  â”œâ”€ figures/     # Plots for README & reports
â”‚  â””â”€ results/     # Metrics, tables, model cards
â”œâ”€ src/co2_emissions/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ data.py      # Data loading, cleaning, merging
â”‚  â”œâ”€ features.py  # Feature engineering utilities
â”‚  â”œâ”€ modeling.py  # Statistical & Bayesian models
â”‚  â”œâ”€ viz.py       # Plotting functions
â”œâ”€ scripts/
â”‚  â”œâ”€ make_dataset.py  # CLI: Build processed dataset
â”‚  â”œâ”€ train.py         # CLI: Train models
â”‚  â”œâ”€ forecast.py      # CLI: Forecast & plot results
â”œâ”€ models/             # Saved model traces
â””â”€ tests/              # Unit tests (if implemented)

ðŸš€ Quickstart

1. Clone the repository:

git clone https://github.com/YOUR_USERNAME/co2-emissions-forecasting.git
cd co2-emissions-forecasting

2. Install dependencies:

pip install -r requirements.txt

ðŸ“Š Workflow

Step 1 â€” Place raw datasets in data/raw/

Required CSV files include:

owid-co2-data.csv
annual-deforestation.csv
annual-temperature-anomalies.csv
average-precipitation-per-year.csv
co2-fossil-plus-land-use.csv
Drought affected annual number.csv
GDP By Country.csv
land-use-over-the-long-term.csv
per-capita-co2-sector.csv
refined_countries.csv

Step 2 â€” Build cleaned dataset:

python scripts/make_dataset.py --source data/raw --out data/processed

Step 3 â€” Train models:

Population trend model:
python scripts/train.py --data data/processed/Master_filtered_df_cleaned.csv \
                        --models models \
                        --country Latvia \
                        --model pop-trend
COâ‚‚ vs GDP + Year model:
python scripts/train.py --data data/processed/Master_filtered_df_cleaned.csv \
                        --models models \
                        --country China \
                        --model co2-gdp

Step 4 â€” Forecast:

python scripts/forecast.py --data data/processed/Master_filtered_df_cleaned.csv \
                           --trace models/China_co2_gdp.nc \
                           --country China \
                           --horizon 10
                           
ðŸ“ˆ Example Outputs

EDA: Correlation heatmaps, distribution plots (log & raw)
Model Fits: Posterior parameter estimates from Bayesian regression
Forecasts: 10-year predictions with credible intervals
Insights: Top emitters, deforestation intensity trends

ðŸ›  CLI Commands Overview

Command								Description
python scripts/make_dataset.py	Build cleaned dataset from raw CSVs
python scripts/train.py	Train Bayesian model (pop-trend or co2-gdp)
python scripts/forecast.py	Forecast and plot results from a trained model

ðŸ“œ Methods

EDA: Data completeness checks, null interpolation, correlation analysis, log transformations.
Modeling: Bayesian regression with PyMC using Studentâ€™s t-distribution for heavy-tailed data; GDP and year as predictors.
Evaluation: RÂ², MSE, and visual inspection of prediction intervals.

ðŸ“š Dependencies

Python 3.10+
pandas, numpy, matplotlib, seaborn
PyMC, ArviZ, scipy, scikit-learn

ðŸ“œ License
MIT License â€” see LICENSE for details.

ðŸ™Œ Acknowledgements
Data sourced from Our World in Data and other open sources.